{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis and Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Time series forecasting*** is performed in nearly every organization that works with\n",
    "quantifiable data.  \n",
    "- Retail stores use it to forecast **sales**.\n",
    "- Energy companies use it to\n",
    "forecast reserves, production, **demand**, and prices.  \n",
    "- Educational institutions use it to forecast **enrollment**. \n",
    "- Governments use it to forecast **tax receipts** and spending.  \n",
    "- Transportation companies use time series forecasting to forecast future **travel** and this is actually the type of study we will go into detail later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a time series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A time series is a series of data points indexed (or listed or graphed) in **time order**. Most commonly, a time series is a sequence taken at successive **equally spaced points** in time. Thus it is a sequence of discrete-time data. Examples of time series are : \n",
    "- heights of ocean tides  \n",
    "- monthly sales of a company  \n",
    "- the daily closing value of the Dow Jones Industrial Average.  \n",
    "\n",
    "Time series data have a natural **temporal ordering**. This makes time series analysis distinct from **cross-sectional** studies, in which there is no natural ordering of the observations   \n",
    "(e.g. explaining people's wages by reference to their respective education levels, where the individuals' data could be entered in any order)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time series analysis** comprises methods for analyzing time series data in order to extract meaningful statistics and other characteristics of the data.   \n",
    "\n",
    "**Time series forecasting** is the use of a model to predict future values based on previously observed values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The are two main types of forecasting methods that\n",
    "are popular in business applications.  \n",
    "- **Regression methods** where the user specifies a certain model and then estimates\n",
    "it from the time series. \n",
    "- **Smoothing methods** where the method learns patterns from the data. \n",
    "\n",
    "It is worth noting that data mining methods such as **neural networks** and others that are intended\n",
    "for cross-sectional data are also sometimes used for time series forecasting, especially for incorporating external information into the forecasts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A popular approach for improving predictive performance is to \n",
    "**combine forecasting methods**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Combining forecasting methods can be done\n",
    "via two-level (or multi level) forecasters, where the first method uses the original time series to generate forecasts of future values, and the second method uses\n",
    "the **residuals** from the first model to generate forecasts of future forecast errors,\n",
    "thereby “correcting” the first level forecasts.  \n",
    "-  Another combination approach is via **“ensembles**”, where multiple methods are applied to the time series, and their resulting\n",
    "forecasts are averaged in some way to produce the final forecast.  \n",
    "The\n",
    "averaging across multiple methods can lead to forecasts that are more **robust** and\n",
    "of higher precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both types of forecasting methods, regression models and smoothing, and in\n",
    "general, it is customary to dissect a time series into four components:  *level ,trend , seasonality and noise* . \n",
    "\n",
    "- **Level** describes the average value of the series.  \n",
    "- **Trend** is the change in\n",
    "the series from one period to the next.  \n",
    "- **Seasonality** describes a short-term\n",
    "cyclical behavior of the series which can be observed several times within the\n",
    "given series  \n",
    "- **Noise** is the random variation that results from measurement\n",
    "error or other causes not accounted for. It is always present in a time series to\n",
    "some degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Partitioning and Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the case of cross-sectional data, in order to avoid **overfitting** and to be able\n",
    "to assess the predictive performance of the model on new data, we first partition\n",
    "the data into a **training set** and a **validation set** (and perhaps an additional test set).  \n",
    "- In cross-sectional data, the partitioning is\n",
    "usually done **randomly**, with a random set of records designated as training data\n",
    "and the remainder as validation data.  \n",
    "- However,in time series analysis ,the series is trimmed\n",
    "into **two periods**; the earlier period is set as the training data and the later period\n",
    "as the validation data. Methods are then trained on the earlier training period,\n",
    "and their predictive performance assessed on the later validation period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation measures typically use the same metrics used in cross-sectional evaluation\n",
    "(see Chapter 5) with **MAE, MAPE,** and **RMSE** being the most popular metrics\n",
    "in practice.  \n",
    "\n",
    "In evaluating and comparing forecasting methods, another important tool is **visualization**: examining time plots of the actual and predicted series\n",
    "can shed light on performance and hint toward possible improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Future Forecasts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important difference between cross-sectional and time-series partitioning occurs when creating the actual forecasts. Before attempting to forecast\n",
    "future values of the series, **the training and validation sets are recombined into\n",
    "one long series**, and the chosen method/model is rerun on the complete data.\n",
    "This final model is then used to forecast future values. The three advantages in\n",
    "recombining are:  \n",
    "1.  The validation set, which is the most recent period, usually contains the\n",
    "most valuable information in terms of being the **closest in time to the\n",
    "forecast period**;  \n",
    "2. With more data (the complete time series compared to only the training\n",
    "set), some models can be estimated more **accurately**;  \n",
    "3. If only the training set is used to generate forecasts, then it will require\n",
    "forecasting **farther into the future** (e.g., if the validation set contains four\n",
    "time points, forecasting the next period will require a 5-step-ahead forecast from the training set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of time series with trend and seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following time series data (Amtrak ridership) seems to have a **polynomial trend** (using predictors $t$ and $t^2$) and **monthly seasonality**.  \n",
    "In general, any type of trend shape can be fit as long as it has a mathematical\n",
    "representation. However, the underlying assumption is that this shape is applicable throughout the period of data that we have and also during the period that\n",
    "we are going to forecast.  \n",
    "<img src=\"ridership.png\">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned earlier,a seasonal pattern in a time series means that observations that fall in some\n",
    "seasons have **consistently** higher or lower values than those that fall in other seasons.\n",
    "\n",
    "**Seasonality** is captured in a regression model by creating a new **categorical\n",
    "variable** that denotes the season for each value. This categorical variable is then\n",
    "turned into **dummies**, which in turn are included as predictors in the regression\n",
    "model.  \n",
    "\n",
    "Using both the polynomial trend and monthly seasonality , our regression line seems to fit the data pretty well.  \n",
    "<img src=\"trendandseasonality.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelation and ARIMA models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use **linear regression** for time series forecasting, we are able to account\n",
    "for patterns such as trend and seasonality. However, ordinary regression models\n",
    "do not account for **dependence between values in different periods**, which in\n",
    "cross-sectional data is assumed to be absent.   \n",
    "Yet, in the time series context,values in neighboring periods tend to be correlated. Such correlation, called\n",
    "**autocorrelation**, is informative and can help in improving forecasts.\n",
    "\n",
    "If we know\n",
    "that a high value tends to be followed by high values (positive autocorrelation),\n",
    "then we can use that to adjust forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute autocorrelation, we compute the correlation between the series and\n",
    "a **lagged version** of the series.  \n",
    "<img src=\"lagged.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autocorrelation plot for lags 1-12 of the Amtrak ridership data is shown below.Observe the strong **negative lag 6** autocorrelation.This indicates a bi-annual pattern in ridership,\n",
    "with 6-month switches from high to low ridership.  \n",
    "<img src=\"acf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few typical autocorrelation behaviors that are useful to explore are:  \n",
    "- **Strong autocorrelation (positive or negative) at a lag k larger than 1**\n",
    "and its multiples (2k, 3k, . . .) typically reflects a cyclical pattern.  \n",
    "- **Positive lag-1 autocorrelation** (called “stickiness”) describes a series\n",
    "where consecutive values move generally in the same direction.  \n",
    "- **Negative lag-1 autocorrelation** reflects swings in the series, where high\n",
    "values are immediately followed by low values and vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation for residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to looking at the autocorrelation of the raw series, it is very useful\n",
    "to look at the **autocorrelation of the residual series**.   \n",
    "\n",
    "For example, after fitting\n",
    "a regression model (or using any other forecasting method), we can examine\n",
    "the autocorrelation of the series of residuals. If we have adequately modeled\n",
    "the seasonal pattern, then the residual series should show **no autocorrelation**\n",
    "at the season’s lag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is some autocorrelation present in the residuals series (like in the picture below),we can sometimes use that information to improve our forecasts.  \n",
    "<img src=\"residualacf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Forecasts by Integrating Autocorrelation Information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, there are two approaches to taking advantage of autocorrelation.  \n",
    "- One\n",
    "is by directly building the autocorrelation into the regression model\n",
    "other is by  \n",
    "- Constructing a second-level forecasting model on the residual series.  \n",
    "\n",
    "Among regression-type models that directly account for autocorrelation are\n",
    "**autoregressive (AR) models**, or the more general class of models called **ARIMA\n",
    "(Autoregressive Integrated Moving Average) models.** \n",
    "\n",
    "AR models are similar to\n",
    "linear regression models, except that the predictors are the **past values** of the\n",
    "series. For example, an autoregressive model of **order 2**, denoted AR(2), can be\n",
    "written as  \n",
    "<center> $Y_t=b_0 + b_1 Y_{t-1}+ b_2 Y_{t-2} + \\epsilon$</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ARIMA models isn't a very straightforward task.Even with the\n",
    "simpler AR models, fitting them to raw time series that contain patterns such as\n",
    "trends and seasonality requires the user to perform several initial **data transformations** and to choose the order of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**--------------MAYBE SHOW ARIMA INFO MAYBE NOT----------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we do discuss one particular use of AR models that is straightforward to apply in the context of forecasting, which can provide a significant\n",
    "improvement to short-term forecasts. This relates to the second approach for\n",
    "utilizing autocorrelation, which requires constructing a **second-level forecasting\n",
    "model for the residuals**, as follows:  \n",
    "1. Generate a k-step-ahead forecast of the series $(F_{t+k})$, using any forecasting method  \n",
    "2. Generate a k-step-ahead forecast of the forecast error (residual) $(E_{t+k)}$,\n",
    "using an AR (or other) model  \n",
    "3. Improve the initial k-step-ahead forecast of the series by adjusting it\n",
    "according to its forecasted error: \n",
    "<center>Improved $F_{t+k} = F_{t+k} + E_{t+k}$</center>  \n",
    "\n",
    "By fitting the\n",
    "series of residuals, rather than the raw series, we avoid the need for <b>initial data\n",
    "transformations</b> (because the residual series is <b>not expected to contain any trends\n",
    "or cyclical behavior</b> besides autocorrelation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**--------------MAYBE SHOW SMOOTHING METHODS MAYBE NOT----------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our case study : Forecasting Public Transportation Demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecasting transportation demand is important for multiple purposes such as\n",
    "staffing, planning, and inventory control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A public transportation company is expecting an increase in demand for its services and is planning to acquire new buses and to extend its terminals. These\n",
    "investments require a reliable forecast of **future demand**. To create such forecasts,\n",
    "one can use data on historic demand. The company’s data warehouse has data on\n",
    "each 15-minute interval between 6:30 and 22:00, on the number of passengers\n",
    "arriving at the terminal.   \n",
    "<img src=\"ourdata.png\">\n",
    "We have been asked to create a forecasting method that can generate **forecasts for the number of passengers**\n",
    "arriving at the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first choice was the popular ARIMA model.However,to our surprise it preformed very poorly.We tried implementing it the manual way,which includes doing certain data transformations (e.g. log of the series) in order to obtain some parameters for the model (p,d,q) but that gave us very bad performance on the validation set.We also tried the auto.arima R function which returns best ARIMA model according to either AIC, AICc or BIC value which all are estimators of the relative quality of statistical models.  \n",
    "<img src=\"arima.png\">\n",
    "After doing some research we found that the issue was that our timeseries was a little special in a way.As we previously said,timeseries in general have four components :level,trend,seasonality and a random factor.Well we can actually use R to decompose a timeseries into it's components.Here's what we got.  \n",
    "<img src=\"decomp.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the trend component has a seasonal pattern in it self.It represents the weekly seasonality of the timeseries.That means that our data has **multiple seasonality**,one is daily and the other is weekly.According to Rob J. Hyndman who is an expert in statistical analysis of timeseries,**there are no R packages that handle multiple seasonality for ARIMA models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also tried smoothing methods like the **Holt-Winters’** seasonal method but that also failed.According to mr Hyndman again *\"The Holt-Winters method is a poor choice for weekly data. It involves estimating a parameter for each week so the model has far too many degrees of freedom.\"*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After searching for methods that account for multiple seasonality we were lead to the **TBATS model** introduced by De Livera et al (JASA, 2011). This uses a state space model that is a generalization of those underpinning exponential smoothing. It also allows for automatic Box-Cox transformation and ARMA errors. The modelling algorithm is entirely automated.The TBATS model was able to capture the multiple seasonality as you can see by the decomposition below.  \n",
    "<img src=\"tbatsdecomp.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However when running the model to make predictions,we weren't satisfied with the result.  \n",
    "<img src=\"tbats.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if we manually fixed the negative demand predictions at weekends,the model's predictions still don't look right.Also,it being an automatically calculated model,we had no control over it.So we decided to build **our own model!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modeled the daily seasonality with a categorical variable that has 62 levels since there are 62 different observations in a day.For the weekly seasonality we used another categorical variable with 2 levels:one for weekends and one for weekdays.Our model was a multiplicative linear model with interactions between the first seasonal variable and the second one.The coefficients of the linear model were 1 for the intercept plus 1 for the daytype (weekend or weekday) plus 62 for the daily seasonal dummies plus another 62 for the interaction between the daily seasonal dummies and the daytype.So a total of 126 parameters.\n",
    "\n",
    "The results were already pretty good but not good enough.  \n",
    "<img src=\"daytype.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see ,all weekdays are on the same level which doesn't happen in the original timeseries.Same goes for the weekends.You can even see it from the residuals that there is a pattern in the weekdays and weekends.\n",
    "\n",
    "<img src=\"resid1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This observation led us to create yet another dummy variable for the day of the week with 7 levels (one for each day).Our model now uses interactions between 3 variables to calculate the demand.This time the parameters are even higher in amount but the results are very good.  \n",
    "<img src='finalmodel1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residuals on weekdays and weekends are now a lot more random.The weekend residuals are smaller than the weekday residuals because **weekends have significantly less demand than weekdays**.If they were equal that would mean that we either did a poor job on predicting weekends,or did an absurdly good job on predicting weekdays.All in all,the weekend and weekday residuals are **almost random** (separately) which means our model captured the structure of the data pretty well.  \n",
    "<img src='residfinal.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we present the final model results and performance metrics ,let's briefly look at some of the experiments we did with variations of our model.  \n",
    "- The first one is using a **different number of seasons** which turned out bad.Any number different than 62 which is the number of observations per day gave worse results.Below is the fit of a model with 4 seasons (we split the day into 4 parts).  \n",
    "<img src='lessseasons.png'>  \n",
    "- Another experiment which we expected to improve our results was using **two different models**:one for weekends and another for weekdays.Below is the fit of the two models.\n",
    "<img src='weekdaymodel.png'>\n",
    "<img src ='weekendmodel.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the fit looks good,the actual performance metrics that we used (R-squared ,MAE) were worse.We don't have a certain explanation why that is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our final model is a linear combination of all of the terms below(except for the first one which is what we are predicting).\n",
    "<img src='parameters.png'>  \n",
    "The reason why we dont include a **trend** component is because after comparing average demand from week to week,we saw very small changes which we decided are too insignificant to include in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics and problem with MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The first metric we will use is the **adjusted R squared** which is normal R squared with an adjustment for penalizing a high number of predictors.\n",
    "<img src=\"rsquare.png\" >\n",
    "\n",
    "**Training set** : 0.9262  \n",
    "**Validation set**:0.6170 (we will improve it later)   \n",
    "\n",
    "- The next metric is the **Mean Absolute Error**\n",
    "<img src='mae.jpg' alt=\"Drawing\" style=\"width: 600px;\"/>  \n",
    "\n",
    "\n",
    "**Training set** : 3.474  \n",
    "**Validation set**:5.393"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The final metric we were asked to use was the **Mean Absolute Percentage Error** \n",
    "<img src= 'mape.png'  style=\"width: 450px;\"/>  \n",
    "\n",
    "The obvious problem with the MAPE is that it divides by the actual observation,which in our case is demand and we have a lot of cases where demand = 0.  \n",
    "<img src=\"mapeerror.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the APE column in the dataframe above,in observations where demand is zero our APE gets divided by 0 and is therefore **infinite**.To avoid that,we decided to assign out own error for these cases.As you can see from the small demo below,when we have a predicted observation of 8 and we change the actual demand from 8 to 1, our APE is increasing and that increase is **roughly** a doubling.So we decided to divide by 0.5 in the cases of zero demand to somewhat retain that increase pattern.  \n",
    "\n",
    "We should note that this is a sketchy workaround but an even more important note is that MAPE is **not a good metric** for our case.It is very sensitive to certain cases where we didn't make that bad of a prediction and it is extremely sensitive in some cases where our data has unusual values (anomalies) which we will look at later.These cases skyrocket the MAPE and make it an unfair metric for this study.  \n",
    "<img src=\"mapefix.png\">  \n",
    "So after doing the workaround the final values are below.Notice the absurd MAPE on the validation set.  \n",
    "\n",
    "**Training set** :28.786  \n",
    "**Validation set**:160.446"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned earlier we have some unusual observations in the data set,that **we can't account for** and they decrease the performance metrics of our model for no good reason (especially MAPE).  \n",
    "\n",
    "There are instances where demand is **zero at classic high demand times** which is probably due to external factors that we can't predict and include in our model.We also see a few **unusual peaks** of demand where our model under estimated and those are probably due to special events/occasions when people flood to public transportation.  \n",
    "<img src=\"unusual.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the final version of the model that produced our predictions.It is now fit both on the training and the validation data.  \n",
    "<img src=\"finalfit1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we were quite satisfied with our model,we didn't like the fact that it has so **many predictors**.After taking a look at the summary of the model,we found out that the majority of the predictors had a very **high p-value** and were therefore less significant than others.  \n",
    "<img src=\"pval.png\">  \n",
    "\n",
    "So what we decided to do was to iteratively remove the predictor with the highest p-value from our model while keeping track of the adjusted R-squared and making sure that we stop when we try to remove a predictor with a p-value less than 0.05.  \n",
    "<img src=\"removal.png\">  \n",
    "Adjusted R squared increased from **0.617 to 0.766** for the validation period with the removal of insignificant predictors.The total number of predictors decreased from 250 to 120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at a portion of the final coefficients that includes all the interactions between season and daytype as well as all interactions between season and day.\n",
    "\n",
    "<img src=\"coef.png\">\n",
    "\n",
    "What we can observe from the final coefficients is that for roughly the **first half of the seasons**, the interaction between **season and daytype** is insignificant.This means that the behavior of demand is roughly the same for the first half of the day regardless if its a weekday or weekend.Same goes for **day and season**.Meaning that we have the same behavior for the first half of the day regardless of what day it is.The difference happens mostly at the second half of the day which includes the high demand period(around 18:30)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics for this model are:\n",
    "\n",
    "| **Metric \\ Set**  |**Training set**   |   **Validation set** |\n",
    "|---|---|---|\n",
    "|**Adjusted R squared**   | 0.932  | 0.766  |\n",
    "| **MAE**  | 3.832  | 5.478  |\n",
    "| **MAPE**  | 46.394  | 166.457  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally,here is the fit of the model to both the training and the validation set and the forecasts it produced for the next 3 days.  \n",
    "\n",
    "<img src=\"finalfit2.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
